<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Simon Bedford</title><link href="https://simonb83.github.io/" rel="alternate"></link><link href="https://simonb83.github.io/feeds/data-science.atom.xml" rel="self"></link><id>https://simonb83.github.io/</id><updated>2017-02-08T19:30:00-06:00</updated><entry><title>38 Millones de Viajes en Ecobici</title><link href="https://simonb83.github.io/38-millones-de-viajes-ecobici.html" rel="alternate"></link><published>2017-02-08T19:30:00-06:00</published><updated>2017-02-08T19:30:00-06:00</updated><author><name>Simon Bedford</name></author><id>tag:simonb83.github.io,2017-02-08:38-millones-de-viajes-ecobici.html</id><summary type="html">&lt;p&gt;Esta publicación está inspirada en el trabajo fantástico de Todd Schneider de enero del 2016: &lt;a href="http://toddwschneider.com/posts/a-tale-of-twenty-two-million-citi-bikes-analyzing-the-nyc-bike-share-system/"&gt;A Tale of Twenty-Two Million Citi Bike Rides: Analyzing the NYC Bike Share System&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Aprendí una gran cantidad estudiando el trabajo de Todd, y me inspiró  a intentar un análisis similar del sistema de bicicletas públicas en la Ciudad de México, que se llama 'Ecobici'.&lt;/p&gt;
&lt;p&gt;No solo me fascinaba ver de manera detallada cómo se usan las bicicletas en el día a día,  pero también me dio gusto tener la oportunidad de aprender a usar herramientas y técnicas nuevas. &lt;/p&gt;
&lt;p&gt;Algunos de mis análisis son replicaciones casi idénticas del trabajo de Todd usando los datos de Ecobici, aunque son mi propia implementación en Python en vez de R. Por esto estoy increíblemente agradecido con Todd por el haber hecho su trabajo tan públicamente disponible.&lt;/p&gt;
&lt;p&gt;Esta publicación está dividida en las siguientes secciones:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#section1"&gt;Un día en la vida de Ecobici&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section2"&gt;Los datos y el uso de las bicicletas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section3"&gt;¿Dónde están las usuarias?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section4"&gt;Estimaciones de la velocidad&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section5"&gt;Transportes mágicos de bicicletas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section6"&gt;Datos anónimos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section7"&gt;¿Se puede predicir la duración de un viaje?&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;span id="section1"&gt;1. Un día en la vida de Ecobici&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;En cuanto ví la animación de Todd de Nueva York, supe que era algo que yo quería tratar de replicar, no solo porque se veía padre, pero también porque yo creo que da un verdadero sentido de la escala del sistema.&lt;/p&gt;
&lt;p&gt;El enfoque es muy similar: cada punto azul representa un viaje en bicicleta usando las instrucciones de Google Maps para ciclistas.
Obviamente no se puede asumir que la gente necesariamente va a seguir esa ruta, y en muchos casos es muy probable que no irían directo de una estación a otra, sin embargo es un buen comienzo para obtener un sentido de los patrones en los viajes.&lt;/p&gt;
&lt;p&gt;La fecha en cuestión es el miércoles 6 de Abril, la cual es el 3er día más ocupado en la historia de Ecobici; este fue seleccionado porque los dos días más ocupados fueron en el 2015 y quería usar una fecha más reciente para poder tomar en cuenta las construcciones y obras más recientes. &lt;/p&gt;
&lt;p&gt;En total hubo 36,711 viajes ese día, pero para reducir la cantidad de información requerida para la visualización elimine todos los viajes que comenzaron y acabaron en la misma locación, y me enfoque específicamente en viajes en las partes más centrales y al norte de la ciudad (de Roma Sur hacia arriba, lo cual incluye 274 de 452 estaciones) resultando en un total de 26,271 viajes.&lt;/p&gt;
&lt;div id="ecobici_day_in_life" class="map-dynamic"&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
Es bastante hipnotizante ver los puntos azules hacer su camino a través del mapa y ya se puede ver algunas concentraciones de bicicletas (por la brilleza del azul), en particular en la calle principal (Reforma) cortando de manera diagonal la mitad superior del mapa.&lt;/p&gt;
&lt;p&gt;Podemos ir un paso más allá y ver cuales calles salen más frecuentemente dentro de las rutas de Google Maps, basado en el número de viajes que usan ese calle.&lt;/p&gt;
&lt;p&gt;&lt;h5 align="center"&gt;Las calles más populares para viajes en Ecobici&lt;/h5&gt; &lt;/p&gt;
&lt;p&gt;&lt;img alt="popular_bike_routes" src="/images/ecobici_popular_routes.png" /&gt;&lt;/p&gt;
&lt;p&gt;Las calles rojas y gruesas son aquellas que tienen 500 viajes o más. Los puntos anaranjados son estaciones de Ecobici.&lt;/p&gt;
&lt;p&gt;Los estrechos grandes de Reforma, División del Norte y Patriotismo, al igual que una sección al Sur de Felix Cuevas, están claramente marcadas. &lt;/p&gt;
&lt;p&gt;No es sorprendente ver que estas calles aparecieron tan frecuentemente, ya que son calles claves que conectan diferentes partes de la ciudad, y al mismo tiempo tiene una buena cobertura de carriles para bicicletas.&lt;/p&gt;
&lt;p&gt;Una cosa que se me hizo interesante fue ver, como en un solo día, los viajes en bicicleta eran muy probables de cubrir casi todas las calles dentro del area de Ecobici. ¡Al simplemente trazar cada paso, acabamos con un mapa bastante completo de la ciudad!&lt;/p&gt;
&lt;h3&gt;&lt;span id="section2"&gt;2. Los datos y el uso de las bicicletas&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;El sistema de “Ecobici” comenzó en el 2010, y desde entonces ha crecido de manera significativa en términos de uso. Abajo se encuentra una gráfica demostrando el número total de viajes en bicicleta por año: &lt;/p&gt;
&lt;p&gt;&lt;img alt="trips_per_year" src="/images/ecobici_esp_number_of_trips_per_year.png" /&gt;&lt;/p&gt;
&lt;p&gt;El punto de inflexión fue por ahí en el año 2013 cuando el uso de bicicletas explotó con dos y medio veces más viajes en bicicleta comparado con el año anterior. Hasta ahora, el 2015 ha tenido los más altos niveles de uso.&lt;/p&gt;
&lt;p&gt;El número de bicicletas en circulación también ha aumentado poco a poco, con bicicletas nuevas llegando en grandes cantidades cada par de años. &lt;/p&gt;
&lt;p&gt;&lt;img alt="bikes_per_year" src="/images/ecobici_esp_number_of_bikes_per_year.png" /&gt;&lt;/p&gt;
&lt;p&gt;Interesantemente, en el 2016 se añadieron 2,000 bicicletas, a pesar de que el número de paseos no haya incrementado.&lt;/p&gt;
&lt;p&gt;Con un incremento anual de al menos un 15% entre el 2013 y el 2015, puede ser que el operador de Ecobici estaba provisionando para un incremento similar en el 2016 que nunca se concretó. &lt;/p&gt;
&lt;p&gt;Alternativamente, podría ser que había una escasez en el 2015 y por lo tanto las nuevas adiciones fueron simplemente para alcanzar la demanda.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;La Escala de Ecobici&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;El sistema Ecobici funciona de forma similar a los ”ride-shares” existentes en otros países con estaciones fijos donde uno puede recoger y entregar bicicletas. A partir de hoy, hay un total de 452 estaciones de bicicletas alrededor de la ciudad, cubriendo un área de aproximadamente 55 kilómetros cuadrados. &lt;/p&gt;
&lt;p&gt;El sistema opera de Lunes a Domingo de 5AM a 12.30AM todos los días del año, aunque el servicio se ve reducido durante algunos días festivos. &lt;/p&gt;
&lt;p&gt;Al final de Diciembre 2016 había un total de 38,661,411 de viajes en Ecobicis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Los Datos&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Datos mensuales están disponibles para Ecobicis, incluyendo la información a continuación acerca de cada viaje:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fecha y hora del comienzo del viaje&lt;/li&gt;
&lt;li&gt;Fecha y hora del fin del viaje&lt;/li&gt;
&lt;li&gt;Estación de partida&lt;/li&gt;
&lt;li&gt;Estación de entrega&lt;/li&gt;
&lt;li&gt;Género del usuario&lt;/li&gt;
&lt;li&gt;Edad del usuario&lt;/li&gt;
&lt;li&gt;Identificador único de la bicicleta&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El número de viajes mensuales entre Enero del 2013 y Diciembre del 2016, se puede observar a continuación:&lt;/p&gt;
&lt;p&gt;&lt;img alt="monthly_trips" src="/images/ecobici_esp_monthly_bike_trips.png" /&gt;&lt;/p&gt;
&lt;p&gt;Se puede ver que el uso baja considerablemente cada año alrededor de Diciembre...probablemente por las vacaciones de Navidad. En Junio hay decaídas menores, lo cual coincide con el comienzo de la temporada de lluvias.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;El Uso Promedio&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;El número de viajes en bicicleta es mucho más alto entre semana que durante el fin de semana. Los patrones de uso también varían a lo largo del día.&lt;/p&gt;
&lt;p&gt;Entre semana, hay picos claros a las 8AM y 6PM, muy probablemente representando gente viajando hacia y de regreso de su trabajo. También hay un incremento en actividad entre las 2 y 3 PM, lo cual coincide con la hora de la comida para los trabajadores de oficina.&lt;/p&gt;
&lt;p&gt;En los fines de semana, el incremento es más gradual, y la mayor parte de la actividad ocurre entre las 10 AM y las 17 PM.&lt;/p&gt;
&lt;p&gt;&lt;img alt="monthly_trips" src="/images/ecobici_esp_hourly_usage.png" /&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span id="section3"&gt;3. ¿Dónde están las usuarias?&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Las mujeres usan las Ecobicis mucho menos que los hombres, y la diferencia ha estado aumentando:&lt;/p&gt;
&lt;p&gt;&lt;img alt="trips_by_gender" src="/images/ecobici_esp_number_of_trips_per_year_by_gender.png" /&gt;&lt;/p&gt;
&lt;p&gt;Las mujeres que sí usan las Ecobicis tienden a ser más jóvenes, con el 73% teniendo 35 años o menos contra solo un 61% de usuarios masculinos.&lt;/p&gt;
&lt;p&gt;&lt;img alt="age_distribution_by_gender" src="/images/ecobici_esp_age_distribution_by_gender.png" /&gt;&lt;/p&gt;
&lt;p&gt;En promedio, las usuarias femeninas cuentan por un 26% de todos los viajes entre Enero del 2013 y Julio del 2016.&lt;/p&gt;
&lt;p&gt;Nos podemos hacer una idea de los patrones de uso de las mujeres durante el día comparando las proporciones de viajes iniciados por mujeres contra este porcentaje promedio.&lt;/p&gt;
&lt;p&gt;Se puede ver que las mujeres son más probables de usar Ecobicis los fines de semana, particularmente en horario diurno, y menos probables de pasear tarde en la noche o muy temprano en la mañana.&lt;/p&gt;
&lt;p&gt;&lt;img alt="age_distribution_by_gender" src="/images/ecobici_esp_hourly_usage_females.png" /&gt;&lt;/p&gt;
&lt;p&gt;También se puede analizar cómo el uso de Ecobici por las mujeres varía por región de la ciudad. Un posible método es calcular los porcentajes por género de los viajes comenzadas en las diferentes estaciones, sin embargo el problema con esto es que en muchos áreas las estaciones están muy cercas una de la otra, lo cual complica poder distinguir patrones con facilidad.&lt;/p&gt;
&lt;p&gt;Otra opción puede ser agrupar las estaciones por colonia, y ver la distribución de género por cada colonia; sin embargo hay varias colonias muy grandes dentro del rango de Ecobici, por lo tanto este enfoque no captura todo el detalle.&lt;/p&gt;
&lt;p&gt;Al final decidí dividir la ciudad en hexágonos, agrupando estaciones de Ecobici por hexágono. Cada uno tiene una anchura de 800m y cubre un área de aproximadamente 0.4 km cuadrados, resultando en un total de 112 hexágonos cubriendo las partes de la ciudad con estaciones de Ecobici. El número mediano de estaciones por hexágono es 4.&lt;/p&gt;
&lt;p&gt;A continuación hay un mapa demostrando los porcentajes de viajes iniciados por mujeres dentro de cada hexágono:&lt;/p&gt;
&lt;p&gt;&lt;img alt="female_usage_by_area" src="/images/ecobici_esp_female_usage_by_hexagon.png" /&gt;&lt;/p&gt;
&lt;p&gt;Se puede observar que el uso por mujeres está particularmente concentrada alrededor de la Colonia Roma y áreas de la Condesa, y el uso está por debajo del promedio dentro y alrededor del Centro y la Colonia Cuauhtemoc.&lt;/p&gt;
&lt;h3&gt;&lt;span id="section4"&gt;4. Estimaciones de la velocidad&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;No entraré a mucho detalle acerca de la velocidad de los viajes, sin embargo es interesante ver como la velocidad puede variar según edad y género.&lt;/p&gt;
&lt;p&gt;A pesar de que la velocidad no está incluida entre los datos brutos, se puede estimarlo usando el tiempo de comienzo y terminación del paseo, junto con los datos de rutas de Google Maps.&lt;/p&gt;
&lt;p&gt;La gráfica abajo plantea la velocidad promedia estimada por género y edad, tanto durante la semana como los fines de semana. &lt;/p&gt;
&lt;p&gt;&lt;img alt="ecobici_avg_speed" src="/images/ecobici_esp_avg_speed.png" /&gt;&lt;/p&gt;
&lt;p&gt;(Nota que el análisis de estas gráficas ignora todos los viajes con una duración menor a 60 segundos en total, y restringe la edad del usuario a 65 años o menos.)&lt;/p&gt;
&lt;p&gt;Lo primero que se puede ver es que, en promedio, los usuarios masculinos consistentemente van más rápido que las usuarias femeninas, y que en ambos sexos, los usuarios jóvenes van más rápido que los usuarios mayores (las dos cosas no son tan sorprendentes).&lt;/p&gt;
&lt;p&gt;También se puede ver que los viajes durante el fin de semana son más bien por el gusto de pasear en bici, con una velocidad en general más baja por aproximadamente 1-2 km por hora.&lt;/p&gt;
&lt;p&gt;Obviamente esto asume que el usuario sigue la ruta sugerida por Google y que no hace ninguna parada a lo largo del camino. &lt;/p&gt;
&lt;h3&gt;&lt;span id="section5"&gt;5. Transportes mágicos de bicicletas&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Cuando se ejecuta un servicio como Ecobici, una cuestión logística interesante es cómo manejar la oferta y demanda de las bicicletas en cada estación. Inevitablemente, cuando los usuarios han ido de paseo, no todas las bicicletas acabaran en una locación ideal, y podría ser necesario que el operador tenga que transportar bicicletas de una estación a otra para equilibrar la oferta. &lt;/p&gt;
&lt;p&gt;Se puede ver como esto funciona con cierto detalle al analizar los viajes en bici que comienzan en una estación diferente a la que habían sido previamente entregadas. Todd llama a estos ‘transportes mágicos’.&lt;/p&gt;
&lt;p&gt;Aquí hay una gráfica de los transportes mágicos, visto como un porcentaje del total de los viajes por mes:   &lt;/p&gt;
&lt;p&gt;&lt;img alt="magical_transports_by_month" src="/images/ecobici_esp_magical_transports_by_month.png" /&gt;&lt;/p&gt;
&lt;p&gt;Entre el 2012 y 2014, la proporción fue más o menos constante entre 16 a 17%, y después se cayó fuertemente en el 2015, tal vez porque el número de bicicletas casi se dobló (desafortunadamente no tengo datos sobre cuando comenzaron a operar las diferentes estaciones, o si su capacidad haya cambiado durante el tiempo).&lt;/p&gt;
&lt;p&gt;Curiosamente, el porcentaje de transportes mágicos se ha incrementado de nuevo durante el 2016, incluso mientras el número de bicicletas ha continuado aumentar.&lt;/p&gt;
&lt;p&gt;Podemos analizar cuáles son las regiones de la ciudad que tienen una proporción mayor de transportes mágicos, basado en la estación de entrega del viaje:&lt;/p&gt;
&lt;p&gt;&lt;img alt="magical_transports_by_area" src="/images/ecobici_esp_magical_transport_by_hexagon.png" /&gt;&lt;/p&gt;
&lt;p&gt;Parece que los viajes acabando alrededor del Centro y Polanco y también los que terminan en el lado este de la zona Ecobici resultan en más altos niveles de transportes mágicos. &lt;/p&gt;
&lt;p&gt;La necesidad de mover bicicletas de un lugar al otro tiene diferentes patrones a lo largo del día depende de donde termina el viaje. Por ejemplo, para los viajes que terminan en el Centro Histórico los niveles altos de transportes mágicos se extienden a lo largo del día, mientras en el sur están más concentrados en las horas tempranas de la mañana.&lt;/p&gt;
&lt;p&gt;&lt;img alt="magical_transports_by_hour" src="/images/ecobici_esp_magical_transport_by_hour.png" /&gt;&lt;/p&gt;
&lt;p&gt;Por final, podemos analizar las distancias promedias del transporte mágico de bicicletas.&lt;/p&gt;
&lt;p&gt;&lt;img alt="magical_transports_distances" src="/images/ecobici_esp_magical_transport_distances.png" /&gt;&lt;/p&gt;
&lt;p&gt;Parece que, en general, los transportes mágicos tienen una distancia promedia  entre 1 a 3km., aunque hay puntos aislados de bicicletas siendo transportadas casi de un lado al otro de la zona Ecobici.&lt;/p&gt;
&lt;p&gt;Hay una cosa que cabe mencionar sobre los transportes mágicos, lo cual es que puede haber otras razones por las cuales las bicicletas se encuentran en una locación diferente de donde fue entregada, y no siempre será para equilibrar la capacidad. &lt;/p&gt;
&lt;p&gt;Por ejemplo, si una bicicleta es retirada de la circulación por razones de mantenimiento o reparaciones (actualmente aproximadamente un 1% de bicicletas al día), de ninguna manera está garantizado que será regresada a la estación original de donde salió.&lt;/p&gt;
&lt;h3&gt;&lt;span id="section6"&gt;6. Datos anónimos&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Otra cosa que Todd analiza para los “NYC Citibikes” son los datos anónimos, medidos por la proporción de viajes que son únicamente identificables.&lt;/p&gt;
&lt;p&gt;En este caso, cuando hablamos de “anónimo”, no estamos hablando de la presencia de nombres u otros identificadores en los datos, pero del concepto de anonimato que viene de ser parte de una multitud.&lt;/p&gt;
&lt;p&gt;En práctica esto quiere decir que si hay muchos paseos que comparten exactamente las mismas características, y aunque lograras identificar a uno de los usuarios, sería difícil obtener mayor información sobre su viaje en particular.&lt;/p&gt;
&lt;p&gt;Sin embargo, para viajes “únicos”, uno puede obtener información completa fácilmente, incluyendo cosas como locaciones de entrega lo cual te puede decir algo acerca de donde estas personas viven, trabajan, etc.&lt;/p&gt;
&lt;p&gt;Resulta que con tan solo unos pocos variables como:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Edad del usuario&lt;/li&gt;
&lt;li&gt;Sexo del usuario&lt;/li&gt;
&lt;li&gt;Identificación de la estación de partida&lt;/li&gt;
&lt;li&gt;Hora de inicio&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;una gran proporción de los viajes son únicamente identificables.&lt;/p&gt;
&lt;p&gt;Por ejemplo, el 1o de Enero del 2016, solo hubo un paseo a las 8AM de una usuaria femenina de 34 años que comenzó en la estación 182.&lt;/p&gt;
&lt;p&gt;Abajo hay una gráfica de los porcentajes de viajes únicamente identificables por género y edad.&lt;/p&gt;
&lt;p&gt;&lt;img alt="unique_trips" src="/images/ecobici_esp_unique_trips.png" /&gt;&lt;/p&gt;
&lt;p&gt;Como se esperaba, la proporción es más alta para mujeres (hay menos usuarias en total), y también más alto para usuarios mayores (la distribución de edad de usuarios se va aplanando en lo que va incrementando la edad).&lt;/p&gt;
&lt;h3&gt;&lt;span id="section7"&gt;7. ¿Se puede predicir la duración de un viaje?&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Como una pregunta final, me pregunté si era posible predecir la duración de un viaje en particular con los datos disponibles.&lt;/p&gt;
&lt;p&gt;Desde un punto de vista operativo esto podría ser muy útil para planear y manejar la disponibilidad de bicicletas.&lt;/p&gt;
&lt;p&gt;Recuerda que los datos que tenemos disponibles son:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Género&lt;/li&gt;
&lt;li&gt;Edad en años&lt;/li&gt;
&lt;li&gt;Hora y fecha de inicio y terminación del viaje&lt;/li&gt;
&lt;li&gt;Estación de partida y entrega&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;aunque no es apropiado incluir la información acerca de la hora y locación de terminación, ya que el objetivo es predecir la duración por adelantado.&lt;/p&gt;
&lt;p&gt;La duración del paseo no se dé explícitamente, pero se puede calcular con facilidad usando “timestamps” para el tiempo de comienzo y de terminación.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Regresión lineal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Dado lo que sabemos acerca del impacto de género y edad en la velocidad estimada de los viajes, un enfoque simple podría ser tratar esto como un problema de regresión lineal usando estos dos variables.&lt;/p&gt;
&lt;p&gt;Para obtener una idea del éxito que esto podría tener, he graficado la duración del paseo contra la edad del usuario para una muestra aleatoria de 10,000 viajes:&lt;/p&gt;
&lt;p&gt;&lt;img alt="duration_v_age" src="/images/ecobici_esp_duration_v_age.png" /&gt;&lt;/p&gt;
&lt;p&gt;Es claro que no hay una relación lineal, y también se puede ver que en cada edad hay un gran rango de duraciones en los viajes.&lt;/p&gt;
&lt;p&gt;Como el próximo paso, podríamos intentar añadir características adicionales para analizar la duración de los viajes para segmentos mucho más específicos. Por ejemplo, abajo se grafica la distribución de las duraciones para las usuarias femeninas de 25 años, entre semana, partiendo a las 9 AM de 3 estaciones que están cerca una de la otra en Polanco:&lt;/p&gt;
&lt;p&gt;&lt;img alt="subset_distribution" src="/images/ecobici_esp_subset_distribution.png" /&gt;&lt;/p&gt;
&lt;p&gt;Hasta para esta subcategoría muy específica, todavía se encuentra un gran rango de duraciones de paseo, y por lo tanto, al parecer sería difícil crear un modelo preciso con los datos disponibles.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Clasificación en “rangos”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Incluso si intentamos resolverlo a través de clasificación en lugar de regresión, continuaría siendo difícil crear un modelo lo suficientemente preciso.&lt;/p&gt;
&lt;p&gt;Por ejemplo, tomando el ejemplo de arriba y usando intervalos de 10 minutos, hay al menos tres posibles clases, y no hay más variables para ayudar a diferenciar entre ellas.&lt;/p&gt;
&lt;p&gt;Si usamos intervalos más pequeños, por ejemplo de 5 minutos, entonces el problema sería aún más dificil; con plazos de tiempo más largos de 20 ó 30 minutos, no obtenemos nada ya que sabemos que la gran mayoría de los viajes duran menos de media hora.&lt;/p&gt;
&lt;p&gt;Para demostrar esto, intenté entrenar un “random forest” (1,000 estimadores) con una muestra aleatoría de 1,000,000 de viajes y usando aproximadamente 120 características consistiendo de:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Género&lt;/li&gt;
&lt;li&gt;Edad&lt;/li&gt;
&lt;li&gt;Indicador de entre semana vs. fin de semana&lt;/li&gt;
&lt;li&gt;Hora de partida&lt;/li&gt;
&lt;li&gt;Mes&lt;/li&gt;
&lt;li&gt;Ubicación de estación de inicio (agrupado por hexágono)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El mejor resultado que obtuve, después de optimizar los parámetros con "cross-validation", fue una precisión menor al 50%.&lt;/p&gt;
&lt;p&gt;Podría ser posible obtener una mejoría pequeña en la precisión, por ejemplo con optimización adicional o usando un modelo capaz de capturar más complejidad, sin embargo no creo que los datos disponibles sean suficientes para crear un modelo predictivo útil.&lt;/p&gt;
&lt;p&gt;Si por otro lado uno tuviera acceso a las historias de viajes de los usuarios individuales, entonces probablemente sería más posible crear un modelo más preciso.&lt;/p&gt;
&lt;h3&gt;Conclusión&lt;/h3&gt;
&lt;p&gt;Cuando empecé este mini-proyecto, pensé que sería relativamente fácil hacer algo similar al análisis de Todd de Nueva York dado a que tenía su codigo para estudiar.&lt;/p&gt;
&lt;p&gt;Al final tomó más tiempo de lo que esperaba, en parte porque tuve que aprender herramientas y técnicas nuevas (por ejemplo POSTGIS y el uso de 'queries' geográficas), pero también porque se me hizo fácil perderme al explorar los datos y buscar otras historias interesantes que contar.&lt;/p&gt;
&lt;p&gt;Inclusive ahora siento que apenas he tocado la superficie de la los datos, y hay mucho más que me gustaría explorar.&lt;/p&gt;
&lt;p&gt;En particular sería interesante ver la distribución temporal de la partida de los viajes por estación, por ejemplo para preguntar cuál es la probabilidad que una bicicleta (o más) será tomada de una estación en particular dentro de un plazo de tiempo específico.&lt;/p&gt;
&lt;p&gt;Uno de los elementos que disfrute en particular mientras estaba escribiendo este post fue meterme más a la parte de mapear. Hubo un momento en particular cuando estaba trazando las instrucciones de Google Maps sobre una página en blanco por primera vez, y de repente un mapa casi completo de la ciudad apareció con todas las calles, glorietas, parques, etc.&lt;/p&gt;
&lt;p&gt;¡Se me hizo muy padre!&lt;/p&gt;
&lt;p&gt;Como siempre, mi código acompañante (por si a alguien más se le haga útil) está en &lt;a href="https://github.com/simonb83/ecobici"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;</summary><category term="data-science"></category><category term="visualization"></category></entry><entry><title>38 Million Ecobici Trips in Mexico City</title><link href="https://simonb83.github.io/38-million-ecobici-trips-mexico-city.html" rel="alternate"></link><published>2017-01-29T19:30:00-06:00</published><updated>2017-01-29T19:30:00-06:00</updated><author><name>Simon Bedford</name></author><id>tag:simonb83.github.io,2017-01-29:38-million-ecobici-trips-mexico-city.html</id><summary type="html">&lt;p&gt;This post is very much inspired by Todd Schneider's fantastic work from early 2016: &lt;a href="http://toddwschneider.com/posts/a-tale-of-twenty-two-million-citi-bikes-analyzing-the-nyc-bike-share-system/"&gt;A Tale of Twenty-Two Million Citi Bike Rides: Analyzing the NYC Bike Share System&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I learned a huge amount from studying Todd's work, and it inspired me to attempt a similar analysis for the public bike share system in Mexico City called 'Ecobici'.&lt;/p&gt;
&lt;p&gt;Not only was it fascinating to take a detailed look at how the bikes are used on a day-to-day basis, but I was also pleased to be able to learn some new tools and techniques.&lt;/p&gt;
&lt;p&gt;Some of my analyses are almost direct replications of Todd's using the Ecobici data, albeit my own implementations using Python rather than R. For these I am incredibly grateful to Todd for making his work so freely available.&lt;/p&gt;
&lt;p&gt;I have split the post into the following sections:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#section1"&gt;A day in the life of Ecobici&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section2"&gt;Data &amp;amp; bike usage overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section3"&gt;Where are all the female riders?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section4"&gt;Speed estimates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section5"&gt;Magical bike transports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section6"&gt;Data anonymity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#section7"&gt;Can you predict trip duration?&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;span id="section1"&gt;1. A day in the life of Ecobici&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;As soon as I saw Todd's animation for NYC, I knew it was something I wanted to try and replicate, not only because it looks so cool, but also because I think it really gives a sense of the scale of the system.&lt;/p&gt;
&lt;p&gt;The approach is very similar, where each blue dot represents a single bike trip as they follow the Google Maps cycling directions between stations.&lt;/p&gt;
&lt;p&gt;Obviously you cannot assume that people will necessarily follow that route, and in many cases they are likely to do other things rather than just riding directly from station to station, however it isn't a bad place to start for getting a sense of the patterns among the trips.&lt;/p&gt;
&lt;p&gt;The date in question is Wednesday 6th April, which is the 3rd busiest day in the history of Ecobici, chosen because the busiest two days are both in 2015 and I wanted to use a more recent date to take into account roadworks and construction that have happened in the meantime.&lt;/p&gt;
&lt;p&gt;In total there were 36,711 trips that day, although in order to try and reduce the amount of data required for the visualization I eliminated all trips starting and ending at the same location, and then specifically focused on trips in the more central and northern part of the city (Roma Sur and upwards, which includes 274 of 452 stations) resulting in a total of 26,271 trips.&lt;/p&gt;
&lt;div id="ecobici_day_in_life" class="map-dynamic"&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
Watching the blue dots make their way across the map is pretty mesmerising and you can already see some bright concentrations of bikes, particularly along a main road (called Reforma) cutting diagonally across the top half of the map.&lt;/p&gt;
&lt;p&gt;We can go one step further and look at what seem to be the most popular roads by mapping the individual legs of the suggested Google Maps routes, weighted by the number of rides that use that leg.&lt;/p&gt;
&lt;p&gt;&lt;h5 align="center"&gt;Most Popular Roads for Ecobici Trips&lt;/h5&gt; &lt;/p&gt;
&lt;p&gt;&lt;img alt="popular_bike_routes" src="/images/ecobici_popular_routes.png" /&gt;&lt;/p&gt;
&lt;p&gt;The thick red roads are those that have 500 or more rides along them. The orange dots are the Ecobici stations.&lt;/p&gt;
&lt;p&gt;Very clearly marked are big stretches of Reforma, División del Norte and Patriotismo, and also a section of Felix Cuevas down in the south.&lt;/p&gt;
&lt;p&gt;It is unsurprising that these would turn up so many times in Google Maps directions as they are all key roads connecting different parts of the city, but also have good coverage with bike lanes.&lt;/p&gt;
&lt;p&gt;One thing I found interesting was how the bike trips during a single day are likely to cover almost every street within the Ecobici area. Just by plotting each of these legs, we end up with a pretty complete map of the city!&lt;/p&gt;
&lt;h3&gt;&lt;span id="section2"&gt;2. Ecobici Data &amp;amp; Overview&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The Ecobici bike share system started in 2010, and since then has grown quite significantly in terms of usage. Here is a chart showing the total number of bike trips per year:&lt;/p&gt;
&lt;p&gt;&lt;img alt="trips_per_year" src="/images/ecobici_number_of_trips_per_year.png" /&gt;&lt;/p&gt;
&lt;p&gt;The inflection point seems to have been around 2013 when bike usage exploded with nearly two-and-a-half times as many bike rides as the previous year. So far, 2015 has seen the highest levels of usage.&lt;/p&gt;
&lt;p&gt;The number of bikes in circulation has also increased steadily, with large numbers of new bikes being added every couple of years or so.&lt;/p&gt;
&lt;p&gt;&lt;img alt="bikes_per_year" src="/images/ecobici_number_of_bikes_per_year.png" /&gt;&lt;/p&gt;
&lt;p&gt;Interestingly, an additional ~2,000 bikes were added in 2016, even as the overall number of rides remained flat.&lt;/p&gt;
&lt;p&gt;With yearly growth of at least 15% between 2013 and 2015, it may be the case that the Ecobici operator was provisioning for similar growth in 2016 that did not materialize.&lt;/p&gt;
&lt;p&gt;Alternatively, it could be that there were bike shortages in 2015 and hence the new additions were simply to 'catch-up' with demand.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ecobici scale&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Ecobici system works similarly to ride-shares in other countries with fixed locations across the city where you can pick-up and drop-off bikes. As of today, there are a total of 452 bike stations across the city covering an area of approximately 55 sq km.&lt;/p&gt;
&lt;p&gt;The system operates Monday - Sunday from 5AM to 12.30AM every day of the year, although there is often reduced service on certain public holidays.&lt;/p&gt;
&lt;p&gt;By the end of December 2016 there had been a total of 38,661,411 trips using Ecobicis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Data&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Monthly data is available for Ecobicis, including the following information for each individual ride:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Trip start date and start time&lt;/li&gt;
&lt;li&gt;Trip end date and end time&lt;/li&gt;
&lt;li&gt;Pickup station&lt;/li&gt;
&lt;li&gt;Drop-off station&lt;/li&gt;
&lt;li&gt;User gender&lt;/li&gt;
&lt;li&gt;User age in years&lt;/li&gt;
&lt;li&gt;Unique bike identifier&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is what the number of monthly rides looks like between January 2013 and December 2016:&lt;/p&gt;
&lt;p&gt;&lt;img alt="monthly_trips" src="/images/ecobici_monthly_bike_trips.png" /&gt;&lt;/p&gt;
&lt;p&gt;You can see that usage falls most heavily around December each year...likely because of the Christmas holidays. There are also smaller drop-offs in rides around June which coincide with the middle of the rainy season.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Average Usage&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The number of bike rides is much higher during the week than at weekends, and usage patterns also vary during the day.&lt;/p&gt;
&lt;p&gt;On weekdays, there are clear peaks around 8 AM and 6 PM, very likely representing morning and afternoon commuters. There is also an increase in activity between 2 and 3 PM which coincides with lunchtime for the typical office-worker.&lt;/p&gt;
&lt;p&gt;On the weekends, the ramp-up is more gradual, and most activity seems to occur between late morning and early evening.&lt;/p&gt;
&lt;p&gt;&lt;img alt="monthly_trips" src="/images/ecobici_hourly_usage.png" /&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span id="section3"&gt;3. Where are all the female riders?&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Women use Ecobicis far less than men, and the gap has been widening:&lt;/p&gt;
&lt;p&gt;&lt;img alt="trips_by_gender" src="/images/ecobici_number_of_trips_per_year_by_gender.png" /&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, female riders tend to be younger, with 73% aged 35 or below, vs. only 61% for males riders.&lt;/p&gt;
&lt;p&gt;&lt;img alt="age_distribution_by_gender" src="/images/ecobici_age_distribution_by_gender.png" /&gt;&lt;/p&gt;
&lt;p&gt;On average, female riders accounted for 26% of all trips between January 2015 and July 2016.&lt;/p&gt;
&lt;p&gt;We can get an idea of female usage patterns during the day by comparing the proportion of rides initiated by women to this percentage, as per the charts below.&lt;/p&gt;
&lt;p&gt;You can see that women are more likely to use Ecobicis at weekends, particularly during daytime hours, and less likely to take rides late at night or very early in the morning.&lt;/p&gt;
&lt;p&gt;&lt;img alt="age_distribution_by_gender" src="/images/ecobici_hourly_usage_females.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can also look at how female Ecobici usage varies by region of the city. One possible approach is to look at the percentage of rides starting at different stations by gender, however the problem with this is that in many areas stations are very close together so it can be hard to easily distinguish patterns.&lt;/p&gt;
&lt;p&gt;Another option could be to group the stations by colonia (neighborhood), and look at the gender distribution for each grouping, however there are a number of quite large colonias within the ecobici coverage, and so this view does not capture all of the underlying detail.&lt;/p&gt;
&lt;p&gt;In the end I decided to use hexagonal bins spread across the city, grouping Ecobici stations by hexagon. Each hexagon has a width of about 800m and covers an area of approximately 0.4 square km, resulting in a total of 112 of hexagons covering the parts of the city with Ecobici stations. The median number of stations per hexagon is 4.&lt;/p&gt;
&lt;p&gt;Below is a map showing the percentage of rides started by females within each hexagonal bin:&lt;/p&gt;
&lt;p&gt;&lt;img alt="female_usage_by_area" src="/images/ecobici_female_usage_by_hexagon.png" /&gt;&lt;/p&gt;
&lt;p&gt;You can see that female usage seems to be particularly concentrated around the Colonia Roma and Condesa areas, and lower than average in and around the Center and Colonia Cuauhtemoc.&lt;/p&gt;
&lt;h3&gt;&lt;span id="section4"&gt;4. Speed Estimates&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;I will not to into a lot of detail about trip speeds, however it is interesting to briefly look at how speed may vary by age and gender.&lt;/p&gt;
&lt;p&gt;Although speed is not included in the raw data, we can make some estimates using the trip start and stop time, along with the obtained Google cycling directions.&lt;/p&gt;
&lt;p&gt;Below are charts plotting the estimated average speed by gender and age for both weekdays and weekends.&lt;/p&gt;
&lt;p&gt;&lt;img alt="ecobici_avg_speed" src="/images/ecobici_avg_speed.png" /&gt;&lt;/p&gt;
&lt;p&gt;Note that in the analyses for these graphs I ignore all trips less than 60 seconds in total, and restrict the rider age to 65 or under.&lt;/p&gt;
&lt;p&gt;The first thing we can see is that it looks like male riders are, on average, consistently faster than female riders, and that in both sexes, younger riders are faster than older ones (both fairly unsurprising findings).&lt;/p&gt;
&lt;p&gt;We can also see that rides taken on weekends are a more leisurely affair, with avg speeds approximately 1-2 km per hour lower across the board.&lt;/p&gt;
&lt;p&gt;Obviously this assumes both that the rider follows the routes 
suggested by Google as well as that they do not make stop-offs along the way.&lt;/p&gt;
&lt;h3&gt;&lt;span id="section5"&gt;5. Magical Transports&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;When running a service like Ecobici, one interesting logistical question is how to manage bicycle supply and demand at each station. Inevitably, once users have taken rides, not all bikes will end up in ideal locations, and it may be necessary for the operator to transport bikes between stations in order to balance out supply.&lt;/p&gt;
&lt;p&gt;We can look at how this works in some detail by analyzing bike rides which start at a different station from the one where they were previously dropped off. Todd calls these 'magical transports'.&lt;/p&gt;
&lt;p&gt;Here is a chart of magical transports as a percentage of overall rides by month:&lt;/p&gt;
&lt;p&gt;&lt;img alt="magical_transports_by_month" src="/images/ecobici_magical_transports_by_month.png" /&gt;&lt;/p&gt;
&lt;p&gt;Between 2012 and 2014, the proportion was fairly steady around 16 or 17%, and then fell sharply in 2015 perhaps because the number of bikes nearly doubled (unfortunately I don't have data on when different stations came into operation, or whether their capacity may have changed over time).&lt;/p&gt;
&lt;p&gt;Curiously, the percentage of magical transports has been creeping up again in 2016, even as the number of bikes in the system has continued to increase.&lt;/p&gt;
&lt;p&gt;We can also look at which regions of the city seem to have a higher proportion of magical transports, based on the station where the trip ends:&lt;/p&gt;
&lt;p&gt;&lt;img alt="magical_transports_by_area" src="/images/ecobici_magical_transport_by_hexagon.png" /&gt;&lt;/p&gt;
&lt;p&gt;There are specific hotspots around the Center and Polanco and it also looks like rides that end along the eastern-side of the Ecobici zone seem to result in higher levels of magical transports.&lt;/p&gt;
&lt;p&gt;The need for moving bikes from one place to another has different patterns throughout the day depending on where the trip ends. For instance, looking at rides ending in the Historic Center and south of the city, you can see that in the south magical transports are quite concentrated in the early hours of the morning, whereas in the Center the higher levels extend much further into the day.&lt;/p&gt;
&lt;p&gt;&lt;img alt="magical_transports_by_hour" src="/images/ecobici_magical_transport_by_hour.png" /&gt;&lt;/p&gt;
&lt;p&gt;Finally, we can also look at approximately how far bikes are transported between rides:&lt;/p&gt;
&lt;p&gt;&lt;img alt="magical_transports_distances" src="/images/ecobici_magical_transport_distances.png" /&gt;&lt;/p&gt;
&lt;p&gt;It seems that the majority of magical transports are somewhere between 1 and 3 km, although there are outliers of bikes being moved almost across the whole Ecobici zone.&lt;/p&gt;
&lt;p&gt;There is one thing that I should note about magical transports which is that there could be other reasons for bikes turning up at a different location from where they are dropped off, and it will not always be due to reblalancing of capacity.&lt;/p&gt;
&lt;p&gt;For example, if a bike is removed from circulation for maintenance or repairs (estimated to be approximately 1% of bicycles on any given day), it is certainly not guaranteed that it will be returned to the original station from where it was taken.&lt;/p&gt;
&lt;h3&gt;&lt;span id="section6"&gt;6. Data Anonymity&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Another thing that Todd looks at for NYC Citibikes is data anonymity as measured by the proportion of uniquely identifiable trips.&lt;/p&gt;
&lt;p&gt;In this case, when we talk about 'anonymity', we are not talking about the presence of names or other such identifiers in the data, but instead the concept that anonymity comes from being part of a crowd.&lt;/p&gt;
&lt;p&gt;What this means in practice is that if there are many trips which share the exact same characteristics, then even if you happen to identify one of the users, it will be hard to obtain further information about their particular ride.&lt;/p&gt;
&lt;p&gt;However, for 'unique' trips, you can easily obtain complete ride information including things like drop-off location which could tell you something about where people live, work etc.&lt;/p&gt;
&lt;p&gt;It turns out that with just a few variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rider age&lt;/li&gt;
&lt;li&gt;Rider sex&lt;/li&gt;
&lt;li&gt;Start station ID&lt;/li&gt;
&lt;li&gt;Start time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;a large proportion of trips are uniquely identifiable.&lt;/p&gt;
&lt;p&gt;For instance, on the 1st of January 2016, there was only one ride starting at 8AM with a Fermale rider aged 34 who started from station number 182.&lt;/p&gt;
&lt;p&gt;Below is a plot of the percentage of uniquely identifiable rides by gender and age:&lt;/p&gt;
&lt;p&gt;&lt;img alt="unique_trips" src="/images/ecobici_unique_trips.png" /&gt;&lt;/p&gt;
&lt;p&gt;As expected, the proportion is higher for women (there are fewer female riders overall), and also higher for older riders (the distribution of user age is flatter as age increases).&lt;/p&gt;
&lt;h3&gt;&lt;span id="section7"&gt;7. Can you predict trip duration?&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;As a final question, I wondered whether it is possible to predict the duration of a particular bike ride given the available data.&lt;/p&gt;
&lt;p&gt;From an operational perspective this could be very useful in order to help with capacity planning and to manage bike availability throughout the network.&lt;/p&gt;
&lt;p&gt;Recall that the available data are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gender&lt;/li&gt;
&lt;li&gt;Age in years&lt;/li&gt;
&lt;li&gt;Start / end time &amp;amp; date&lt;/li&gt;
&lt;li&gt;Start location and end location&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;although it isn't appropriate to include any information about the ride end time or location as the aim is to predict the duration in advance.&lt;/p&gt;
&lt;p&gt;Although trip duration is not explicitly given, we can easily calculate this using the timestamps for the trip start and end time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Linear Regression&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Given what we know about estimated trip speed varying both by age and gender, a very simple approach could be to look at this as a regression problem using these two variables.&lt;/p&gt;
&lt;p&gt;To get an idea of how successful this could by, I plotted trip duration vs. rider age for a random sample of 10,000 rides:&lt;/p&gt;
&lt;p&gt;&lt;img alt="duration_v_age" src="/images/ecobici_duration_v_age.png" /&gt;&lt;/p&gt;
&lt;p&gt;Not only is there clearly no linear relationship, in fact you can see that at each age there is a very large range of trip durations.&lt;/p&gt;
&lt;p&gt;As a next step, we could try and add in additional features to look at trip durations for much more specific subsets of the rides. For example, below is the distribution of ride durations for 25-year-old female users departing from 3 stations close together in Polanco on weekdays at 9AM:&lt;/p&gt;
&lt;p&gt;&lt;img alt="subset_distribution" src="/images/ecobici_subset_distribution.png" /&gt;&lt;/p&gt;
&lt;p&gt;Even for this very specific subset, there is still a wide range of trip-durations and so, on the face of it, it looks like it would be hard to build an accurate model with the available data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Classification in buckets&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Even if we treat this as a classification problem, it still seems that it would be hard to build a sufficiently accurate model.&lt;/p&gt;
&lt;p&gt;For instance, taking the example from above and using intervals of 10 minutes, there are at least three possible classes but no further variables that could help in differentiating between them.&lt;/p&gt;
&lt;p&gt;If we use smaller intervals, of say 5 minutes, then the problem will be even worse, and using longer timeframes of 20 or 30 minutes is just not that useful as we already know that the vast majority of rides last less than half an hour.&lt;/p&gt;
&lt;p&gt;To demonstrate this I tried training a large Random Forest (1000 estimators) on a random sample of 1,000,000 rides using approximately 120 features consisting of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gender&lt;/li&gt;
&lt;li&gt;Age&lt;/li&gt;
&lt;li&gt;Weekday vs Weekend indicator&lt;/li&gt;
&lt;li&gt;Starting hour&lt;/li&gt;
&lt;li&gt;Month&lt;/li&gt;
&lt;li&gt;Start station location (grouped by hexagonal bin)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The best result I was able to obtain, even after some parameter optimisation using cross-validation, was an accuracy of less than 50%.&lt;/p&gt;
&lt;p&gt;Ultimately it may be possible to obtain a slight improvement in accuracy, either with additional optimisation or using a model capable of capturing additional complexity, however I don't think that the available data is sufficient to be able to construct a useful predictor.&lt;/p&gt;
&lt;p&gt;If on the other hand you had access to individual ride history, then it would likely be possible to build a far more accurate model for specific users.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;When I started this mini-project, I thought it would be relatively easy to throw something together similar to Todd's NYC analysis given that I had all of his code to study.&lt;/p&gt;
&lt;p&gt;In the end it took a lot longer than I expected, partly because I had to learn some new tools and techniques (e.g., POSTGIS and geographic queries), but also because I found it so easy to lose myself in exploring the data and looking for other interesting stories to tell.&lt;/p&gt;
&lt;p&gt;Even now I feel like I have barely scratched the surface of the dataset, and there are a lot more things I would like to explore.&lt;/p&gt;
&lt;p&gt;In particular, it would be interesting to look at the temporal distribution of rides starting from individual stations, that is to ask what is the probability that a bike (or more) will be taken from a particular station within a given timeframe.&lt;/p&gt;
&lt;p&gt;One of the elements I particularly enjoyed while writing this post was getting more into mapping. There was this one particular moment when I was plotting the various Google Maps directions on a blank canvas for the first time, and low and behold an almost complete map of the city appeared along with easily identifiable roads, roundabouts, parks etc.&lt;/p&gt;
&lt;p&gt;I thought that was pretty cool!&lt;/p&gt;
&lt;p&gt;As usual, my accompanying code (should anyone else find it useful) is on my &lt;a href="https://github.com/simonb83/ecobici"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;</summary><category term="data-science"></category><category term="visualization"></category></entry><entry><title>Recurring Neural Networks and Star Trek</title><link href="https://simonb83.github.io/rnns-star-trek.html" rel="alternate"></link><published>2016-11-28T15:20:00-06:00</published><updated>2016-11-28T15:20:00-06:00</updated><author><name>Simon Bedford</name></author><id>tag:simonb83.github.io,2016-11-28:rnns-star-trek.html</id><summary type="html">&lt;p&gt;Earlier this year I wrote about &lt;a href="/machine-learning-food-classification.html"&gt;Convolutional Neural Networks (CNNs) and their applications to image classification&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As I discussed, CNNs are very powerful for image classification, giving better-than-human results in some cases, however they do not provide a singular solution to any given problem.&lt;/p&gt;
&lt;p&gt;One limitation of CNNs is that they have no notion of time or sequences, that is to say that each prediction is totally independent of any previous predictions.&lt;/p&gt;
&lt;p&gt;&lt;img alt="simple_network" src="/images/rnn1_simple_network.png" /&gt;&lt;/p&gt;
&lt;p&gt;In the diagram above, each input gives an output independent of the other inputs; one could change the order of the inputs and expect to obtain the same output.&lt;/p&gt;
&lt;p&gt;However there are many types of problems for which we may wish to apply machine learning and neural network-based models, but where we need the ability to process and recognize time-dependent sequences.&lt;/p&gt;
&lt;p&gt;One such example is language translation where you might try and process sentences one word at a time, and where the translation of a particular word will depend on the words that came before.&lt;/p&gt;
&lt;p&gt;Similarly, if you want to build a model to describe a scene in an image word-by-word, then you would want the ability to take previous words into account as the model generates the description.&lt;/p&gt;
&lt;p&gt;In fact, these sorts of sequential models are useful for many different problems in Natural Language Processing, as language is inherently sequential and highly context-dependent.&lt;/p&gt;
&lt;p&gt;In this post I will focus on a particular application called Character Level Language modeling where the aim is to build a model capable of generating text one character at a time.&lt;/p&gt;
&lt;p&gt;The approach used is based on supervised learning, and as such we need a training dataset. For this exercise I decided to use the complete scripts of Star Trek: The Next Generation.&lt;/p&gt;
&lt;p&gt;As with the post on CNNs, I will try and keep the explanations relatively non-technical while still getting across the key ideas. If you just want to see the output, you can skip straight to the &lt;a href="part_3"&gt;results&lt;/a&gt; section.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#part_1"&gt;Brief Introduction to Recurring Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#part_2"&gt;Baseline Results Using Markov Chain Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#part_3"&gt;Star Trek Script Generation Using RNNs&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="part_1"&gt;1. Brief Introduction to Recurring Neural Networks&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Fully Connected Neural Networks&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let's start with a quick reminder of what fully-connected neural networks look like.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt neuron_2" src="/images/capstone_neuron_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;The picture above depicts a single 'neuron' which at its core is nothing more than a function which:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Receives input &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Calculate the linear transform &lt;strong&gt;&lt;em&gt;wX + b&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Passes the result through an activation function, &lt;strong&gt;&lt;em&gt;&amp;sum;&lt;/em&gt;&lt;/strong&gt;, in order to produce the output of the neuron&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The idea of the activation function is to add complexity to the model and ensure that neurons do not 'fire' (produce output) all of the time, but only some of the time based on certain conditions.&lt;/p&gt;
&lt;p&gt;The activation functions used in practice often look like these:&lt;/p&gt;
&lt;p&gt;&lt;img alt="activation_functions" src="/images/capstone_activation.png" /&gt;&lt;/p&gt;
&lt;p&gt;A fully-connected neural network is created by combining many of these neurons into layers, and connecting the layers together in such a way that in each layer (except the input and output layers) every neuron is connected to every other neuron in the preceding and following layers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recurring Neural Networks&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If we were to use the neuron above for processing a sequence of inputs, $ x_1, x_2, x_3,... $, it is clear that the model cannot take into account any notion of order or context, as at each step the output is dependent only upon the current input  $ x_t $ and the internal parameters.&lt;/p&gt;
&lt;div class="math"&gt;$$ Output_t = f(x_t) $$&lt;/div&gt;
&lt;p&gt;What we need instead is a model that take into account both the current input  $ x_t $ as well as all of the previous inputs up until that point:&lt;/p&gt;
&lt;div class="math"&gt;$$ Output_t = f(x_1, x_2,..., x_{t - 1}, x_t) $$&lt;/div&gt;
&lt;p&gt;Recurring Neural Networks (RNNs) provide exactly this type of model. The simplest RNN is based on the following set-up:&lt;/p&gt;
&lt;p&gt;&lt;img alt="rnn_neuron_1" src="/images/rnn1_rnn_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here the model has an internal state $ h_t $ which is updated at each time step according to a recurrence relation:&lt;/p&gt;
&lt;div class="math"&gt;$$ h_t = f(h_{t - 1}, x_t) $$&lt;/div&gt;
&lt;p&gt;That is to say that the hidden state at time t is a function of the previous hidden state at time t-1 along with the input $ x_t $, with $ h_{t - 1} $ and $ x_t $ being combined using learnable parameters $ W_{hh} $ and $ W_{xh} $.&lt;/p&gt;
&lt;p&gt;The result of this combination is then passed through an activation function to generate an output.&lt;/p&gt;
&lt;p&gt;In a vanilla Recurring Neural Network, $ tanh $ is used for the activation function, and the hidden state is calculated by:&lt;/p&gt;
&lt;div class="math"&gt;$$ h_t = tanh( W_{hh} .  h_{t-1} + W_{xh} . x_t) $$&lt;/div&gt;
&lt;p&gt;The prediction at time t, $ y_t $, can then be calculated from the current hidden state using a separate set of parameters:&lt;/p&gt;
&lt;div class="math"&gt;$$ y_t = W_{yh} . h_t $$&lt;/div&gt;
&lt;p&gt;The hidden state h, serves to maintain the 'history' of all of the inputs, as at each step the value of h is a function of all of the inputs up until that point.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Simple Example&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To try and illustrate how this can work in practice, I will use a slightly contrived example, but hopefully it will help to demonstrate how we can take advantage of the history of inputs via the hidden state.&lt;/p&gt;
&lt;p&gt;Suppose we wish to construct a very simple timer that activates after 10 steps in time.&lt;/p&gt;
&lt;p&gt;The function will receive 1s as input, representing single steps in time, and suppose it 'activates' once its output becomes greater than 0.5.&lt;/p&gt;
&lt;p&gt;We can model this using the following simplified RNN unit:&lt;/p&gt;
&lt;p&gt;&lt;img alt="rnn_neuron_2" src="/images/rnn1_rnn_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;Note that this is exactly the same as in the definition of the RNN from above, setting $ W_{hh} = 1 $, $ W_{xh} = 0.1 $, and using a step function instead of $ tanh $ as the activation function.&lt;/p&gt;
&lt;p&gt;Setting h to initially be 0, look at what happens to the hidden state and output as each step is processed:&lt;/p&gt;
&lt;table id="rnn_example"&gt;
    &lt;tr&gt;
        &lt;th&gt;Step&lt;/th&gt;
        &lt;th&gt;Input&lt;/th&gt;
        &lt;th&gt;Hidden State&lt;/th&gt;
        &lt;th&gt;Output&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;0&lt;/td&gt;
        &lt;td&gt;-&lt;/td&gt;
        &lt;td&gt;0&lt;/td&gt;
        &lt;td&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.10&lt;/td&gt;
        &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;2&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.20&lt;/td&gt;
        &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;3&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.30&lt;/td&gt;
        &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;4&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.40&lt;/td&gt;
        &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;5&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.50&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;6&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.60&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;7&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.70&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;8&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.80&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;By incorporating all of the history of the inputs into the output of the model, it is possible to obtain this time or sequence-dependent behaviour.&lt;/p&gt;
&lt;p&gt;(Note: in practice, due to computational restraints, it is not normally possible to process all of the input in one go, and 'mini batches' of input are typically used. Thus the value of the hidden state will be based on all of the history of the current mini-batch up until that point, rather than the history of the whole sequence.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LSTM&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I have just described what is really the simplest type of RNN unit used in practice. One of the problems with this model is that is has difficulty learning long-term dependencies within sequences.&lt;/p&gt;
&lt;p&gt;Fortunately there are other types of Recurrent Neural Network units that are a bit more complicated to describe, but that end up being more powerful models. One such unit is called a Long Short Term Memory unit, or LSTM.&lt;/p&gt;
&lt;p&gt;In principle, the idea is the same, whereby at each step we are just applying a recurrence relation, albeit a more complex one. Without going too much into the mathematical details, the basic setup is the following.&lt;/p&gt;
&lt;p&gt;&lt;img alt="lstm_1" src="/images/rnn1_lstm_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;Whereas in a simple RNN we were maintaining and updating a hidden state $ h_t $ at every step, in an LSTM we keep track of two variables: the hidden state $ h_t $ along with an internal cell state $ c_t $.&lt;/p&gt;
&lt;p&gt;The cell state works a bit like an internal memory that can 'remember' or 'forget' things as needed.&lt;/p&gt;
&lt;p&gt;The first step is to decide how much of the previous cell state to forget. In order to do this, the LSTM looks at the incoming value $ x_t $, along with previous hidden state $ h_{t-1} $ and outputs a number between 0 and 1, where 0 means completely forget and 1 means completely remember.&lt;/p&gt;
&lt;p&gt;&lt;img alt="lstm_2" src="/images/rnn1_lstm_2.png" /&gt;&lt;/p&gt;
&lt;p&gt;The second step is to decide how much of the input to keep. Once again, the LSTM looks at the incoming value $ x_t $ and the previous hidden state $ h_{t-1} $ and decides which bits of information to keep, scaled by a certain factor.&lt;/p&gt;
&lt;p&gt;&lt;img alt="lstm_3" src="/images/rnn1_lstm_3.png" /&gt;&lt;/p&gt;
&lt;p&gt;We are now in a position to update the cell's memory, or internal state, $ c_t $:&lt;/p&gt;
&lt;div class="italic"&gt;New Cell State = Remembered Previous State + Kept Input&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img alt="lstm_4" src="/images/rnn1_lstm_4.png" /&gt;&lt;/p&gt;
&lt;p&gt;Finally, we decide how much of the new cell state we want to output, which is based on the recently updated cell state scaled by a particular factor. The scaling factor is again based on the incoming value $ x_t $ and the previous hidden state $ h_{t-1} $.&lt;/p&gt;
&lt;p&gt;&lt;img alt="lstm_5" src="/images/rnn1_lstm_5.png" /&gt;&lt;/p&gt;
&lt;p&gt;If you're feeling a bit confused at this point, don't worry. There's a lot going on and it took me quite a long time to really get my head around this model.&lt;/p&gt;
&lt;p&gt;The LSTM can be summarized more simply:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There is an internal cell state, or memory, c&lt;/li&gt;
&lt;li&gt;At each time step, the cell state is updated:&lt;ul&gt;
&lt;li&gt;Part of the old cell state is 'forgotten'&lt;/li&gt;
&lt;li&gt;Part of the new input is 'kept'&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The output of the cell is based on some of the internal state scaled in a certain way (i.e. only parts of the cell state become output)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="part_2"&gt;2. Baseline Results Using Markov Chain Models&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem Summary&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before moving on, I want to be a bit clearer about what it is that we hope to achieve. I mentioned earlier that the aim is to build a Character Level Language model, capable of generating text.&lt;/p&gt;
&lt;p&gt;In more simple terms, this means that we want to build a model based on individual characters, for example individual letters, spaces, punctuation marks etc., that outputs a prediction for the next character based upon the current character.&lt;/p&gt;
&lt;p&gt;For example, if we were to start with a capital C, we might want the model to proceed as follows:&lt;/p&gt;
&lt;p&gt;&lt;img alt="rnn_neuron_2" src="/images/rnn1_markov_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Data&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The data comes as a single 12 MB text file, containing formatted scripts complete with indentations, newlines, scene descriptions, stage directions etc.&lt;/p&gt;
&lt;p&gt;As such, we would also hope that the model is capable of generating text that obeys the same formatting style:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 7    ANGLE EMPHASIZING PICARD AND DATA
 As Picard turns to Data:
                PICARD
        You will agree, Data, that
        Starfleet&amp;#39;s instructions are
        difficult?
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;Markov Chain Models&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It is worth noting that different types of language generation algorithms have been around for a long time, and a quite common one is based on mathematical models called Markov Chains.&lt;/p&gt;
&lt;p&gt;A Markov Chain is a probabalistic model which has the key property that the future is based only on the present.&lt;/p&gt;
&lt;p&gt;For example, if you were to use a Markov Chain to model some sequence $ x_1, x_2, x_3,...,x_n $, then at any given moment $ i $, the next step $ x_{i + 1} $ is dependent only upon the current state $ x_i $.&lt;/p&gt;
&lt;p&gt;For example, a simple dice-based board game such as Snakes &amp;amp; Ladders is an example of a Markov Chain:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It is probabilistic - your next position is based on the random outcome of a throw of the dice&lt;/li&gt;
&lt;li&gt;Your next position is only dependent on your current position; how you got to where you are now does not make any difference&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Markov Chain Models in Practice&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Building and using a Markov Chain for generating text is actually quite simple. For example, suppose that we start with some simple training text like:&lt;/p&gt;
&lt;p&gt;"Captain Picard and the Enterprise"&lt;/p&gt;
&lt;p&gt;All that is required for building a character-level model is to step through the text one character at a time and create a table of all of the pairs of characters that precede one another.&lt;/p&gt;
&lt;p&gt;For example, for the first few characters:&lt;/p&gt;
&lt;p&gt;'' &amp;rarr; 'C'&lt;/p&gt;
&lt;p&gt;'C' &amp;rarr; 'a'&lt;/p&gt;
&lt;p&gt;'a' &amp;rarr; 'p'&lt;/p&gt;
&lt;p&gt;We end up with the following table:&lt;/p&gt;
&lt;table id="markov_freqs"&gt;
    &lt;tr&gt;
        &lt;th class="col1"&gt;Preceding&lt;/td&gt;
        &lt;th class="col2"&gt;Following&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;''&lt;/td&gt;
        &lt;td class='col2'&gt;C&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;P&lt;/td&gt;
        &lt;td class='col2'&gt;['i']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;i&lt;/td&gt;
        &lt;td class='col2'&gt;['n', 'c', 's']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;E&lt;/td&gt;
        &lt;td class='col2'&gt;['n']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;t&lt;/td&gt;
        &lt;td class='col2'&gt;['a', 'h', 'e']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;C&lt;/td&gt;
        &lt;td class='col2'&gt;['a']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;s&lt;/td&gt;
        &lt;td class='col2'&gt;['e']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt; &lt;/td&gt;
        &lt;td class='col2'&gt;['P', 'a', 't', 'E']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;c&lt;/td&gt;
        &lt;td class='col2'&gt;['a']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;r&lt;/td&gt;
        &lt;td class='col2'&gt;['d', 'p', 'i']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;h&lt;/td&gt;
        &lt;td class='col2'&gt;['e']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;p&lt;/td&gt;
        &lt;td class='col2'&gt;['t', 'r']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;e&lt;/td&gt;
        &lt;td class='col2'&gt;C&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;d&lt;/td&gt;
        &lt;td class='col2'&gt;[' ', ' ']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;n&lt;/td&gt;
        &lt;td class='col2'&gt;[' ', 'd', 't']&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class='col1'&gt;a&lt;/td&gt;
        &lt;td class='col2'&gt;['p', 'i', 'r', 'n']&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Generating new text is as simple as starting with a particular letter, and then using the table to identify what the next character should be at each stage. If there are multiple options we simply pick one at random.&lt;/p&gt;
&lt;p&gt;For example, starting with the letter C, one possible output could be:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Can anteCain En teCa
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
It is also possible to do this using pairs of characters (i.e. 'Ca' &amp;rarr; 'pt', 'ap' &amp;rarr; 'ta' etc.), triplets of characters or even complete words.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Some Results&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To see how well Markov Chains perform in practice, here are some results based on training the model on the complete Star Trek TNG scripts, using single characters, pairs, triplets, 4-grams and 5-grams.&lt;/p&gt;
&lt;p&gt;In each of the following models, I attempted to generate 2,000 characters of text based upon the constructed character transition tables.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Single Character Model&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;STAR TREK: vero rintove is.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
For the single-character model, at first the output was nearly all blank spaces. This is because, due to the script formatting, there are a lot of tabs and newlines, and so as soon as the model generates a some sort of white-space, it will almos certainly continue to follow this with more blank space.&lt;/p&gt;
&lt;p&gt;In the end I had to feed in an initial bit of text, called a 'seed' (in this case 'STAR TREK'), in order to generate anything at all, but even here it only managed a few nonsensical characters before returning only blank space.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pairs of Characters&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;        RIKERTION Bould
to the ENTINUED: (OPTICASTARD
        Yest ashas aways fathe the ded ing to
                                    taptand stor
        We&amp;#39;s flicare effew am crent bel loordents.
Borgantion afteraly, airal.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
Once you start using pairs of characters, the model can output text without needing a seed, however most of it just looks like nonsense.&lt;/p&gt;
&lt;p&gt;The model does seem to start to replicate some of the formatting, such as multiple tabs and newlines, and in some cases there are the briefest hints of Star Trek, such as &lt;em&gt;RIKERTION&lt;/em&gt;, or in other cases &lt;em&gt;DATA&lt;/em&gt; and &lt;em&gt;Borgantion&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Triplets of Characters&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;         CONTINUED: (2)
Picard is gazing)
        Here is walk me to various
ands through than assador
        alling attentitly
        If the recommitting all right problement in he&amp;#39;s not the
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
By the time you get to using triplets of characters, most of the words are recognizably English, even if most of the sentences don't make any sense.&lt;/p&gt;
&lt;p&gt;The formatting overall is much more script-like, and you even start to get things like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;MING STATION - ACT THREE         STAR TREK: &amp;quot;Birthrough a feelian emember One?
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;which could almost be out of a Star Trek episode.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4-Grams&lt;/strong&gt; (four characters in a row)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;40   INT. REPORTER ROOM
Similar containly
        me. I will not serve ident made vine of his look of your has claim, Worf?
Worf REACTS.
            DATA&amp;#39;S VOICE
        immediately that just station as both for Wesley which wears agony others at the cape (o.s.)
        find here -- your name?
Radue could did the doesn&amp;#39;t happened... so now a heavy...
                RIKER
                RIKER
            (to Kareer...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
Using 4-grams, things look even better, with line-numbers (in no particular order), and perhaps even some Klingon (&lt;em&gt;K'MTAR&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5-Grams&lt;/strong&gt; (five characters in a row)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;                STAR TREK: &amp;quot;The Pegasus&amp;quot; REV. 7/17/92 - ACT FIVE                        KAMIE                USS ENTERPRISE - TRANSPORTER EFFECT stars
still accumulated the
window operation&amp;#39;s birth...

       36.
47   OMITTED

39A
39B  ON ALBERT, the faction... she&amp;#39;s heard so much a device. Finally nods. Picard leans closer... It won&amp;#39;t belonged to get them.

No answer would
        narrow-minder of Honor&amp;quot; - REV. 01/26/93 - ACT THREE                          23.

14   INT. MAIN BRIDGE

The computer
        claimed this place.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
Sequences of 5-characters was the most complex Markov Chain model I built, and I think it is pretty amazing how much complexity such a simple model can generate.&lt;/p&gt;
&lt;p&gt;Even though the sequences of words don't really mean anything, the model is capable of generating pretty-well formatted output, it includes a title, numerous line numbers etc. &lt;/p&gt;
&lt;p&gt;Given that such a simple and easy-to-build model can perform this well, we would need an RNN-based model to do significantly better given the increased complexity and required computational power.&lt;/p&gt;
&lt;h3 id="part_3"&gt;3. Star Trek Script Generation Using RNNs&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Training Setup&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In order to train an RNN using the Star Trek data, I used Torch along with a &lt;a href="https://github.com/jcjohnson/torch-rnn"&gt;library&lt;/a&gt; created by Justin Johnson from Stanford University, running on an Amazon Web Services GPU g2.2x Large instance.&lt;/p&gt;
&lt;p&gt;I experimented with a number of network parameters, including trying both simple RNN as well as LSTM units. The best results were based on a network with the following setup:&lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;Basic unit:&lt;/td&gt;
        &lt;td&gt;LSTM&lt;/td&gt;
        &lt;td&gt;See overview above.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Number of layers:&lt;/td&gt;
        &lt;td&gt;3&lt;/td&gt;
        &lt;td&gt;This is the depth of the network, meaning there were three layers stacked on top of each other.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;RNN Size:&lt;/td&gt;
        &lt;td&gt;256&lt;/td&gt;
        &lt;td&gt;This is the number of hidden units in each layer of the network.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Sequence Length:&lt;/td&gt;
        &lt;td&gt;200&lt;/td&gt;
        &lt;td&gt;The size of the sequence used during training; as I mentioned earlier it is not feasible to train on all of the text at the same time. Here the network is trained on sequences of 200 characters.&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;The remaining network parameters were based on defaults as described &lt;a href="https://github.com/jcjohnson/torch-rnn/blob/master/doc/flags.md#preprocessing"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Loss Curve&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As with any suprvised machine learning problem, we already have the 'answer' that the network should output in any given situation, in this case the next character in a sequence.&lt;/p&gt;
&lt;p&gt;During training the idea is to adjust the internal network weights in such a way as to make the actual and desired output as close together as possible. In order to do this we use a loss function that captures how 'wrong' the network is, and so the goal during training is to minimize this loss.&lt;/p&gt;
&lt;p&gt;It is quite common to visualize how the loss evolves over time during training in order to get an idea of how the network is behaving and evolving, whether it is heading in the right direction and whether or not it seems to be improving on its results or has reached some kind of plateau (convergence).&lt;/p&gt;
&lt;p&gt;Below is such a visualization for the best network mentioned above. The red line represents the loss as calculated on the training data being used at each iteration. The blue line represents the loss as calculated on a separate set of data used exclusively for testing or validation purposes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="rnn_neuron_1" src="/images/rnn1_loss_curve.png" /&gt;&lt;/p&gt;
&lt;p&gt;You can see that the training loss starts out relatively high and decreases pretty quickly within the first 5,000 iterations. Both the training and validation loss seem to have leveled out somewhere between iteration 5,000 and 10,000, and they only improve very slightly thereafter.&lt;/p&gt;
&lt;p&gt;You can also see that the red and blue lines are pretty close together. This is a good thing as it is an indicator that the model is not overfitting too much on the training data and is able to generalize reasonably-well to the validation data.&lt;/p&gt;
&lt;p&gt;The noise in the training loss is due to the fact that we are training the model using only subsets of input data, rather than all at the same time. You can imagine that for any given sequence of characters, the internal weights that minimize the output loss will probably not be the same set of weights that optimize the loss for any other sequence.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Generating Text&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So what happens when we generate some text using the RNN (LSTM) model?&lt;/p&gt;
&lt;p&gt;Before looking at some examples, I need to mention another parameter we can control while sampling called the 'temperature', which is in the range $ 0 &amp;lt; temperature &amp;lt;= 1 $.&lt;/p&gt;
&lt;p&gt;In effect the temperature controls how risky or varied the model is in predicting new characters. When the temperature is low, the model tends to make 'safer' but more boring predictions. At high temperatures, the model will take more chances and make more varied predictions, but is also more likely to make mistakes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Temperature = 1&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;49   ANOTHER ANGLE (OPTICAL)

    The outing is enraged, served. Worf, Riker moving
    over on a silent monitor in rage... he&amp;#39;s admired with
    various memory program. Then on his computer connects.

                    BEVERLY
            And now! I don&amp;#39;t reveal it
            off.

                    WORF
            Of course I small provide them.

                    KYLE
            You don&amp;#39;t remember it?

                    GUECHREY
            What is that? But that&amp;#39;s all we
            do as fast...

                    GEOWDER
            Your tent? What&amp;#39;re has you?
            I neededed get more returns to
            travel.

                    DATA
            The descepants will give no
            routine incident. And that Ferengi
            are over enough to assist in
            Four, shuttlecraft.

    Reactions. He walks off from the art of a compartment.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
At the highest temperature we get some pretty well formatted text, but you can see that there are some spelling mistakes: GUECHREY, neededed, descepants.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Temperature = 0.1&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;                    PICARD
                (to com)
            Computer, report to the ship and
            are a little second three three
            hours.

                    PICARD
                (to com)
            The computer readings are all
            there is a second on the ship.

                    PICARD
            I do not know what the contract
            to the ship is a little series.

                    PICARD
                (to com)
            The ship is a possible container
            of the ship and the ship is a
            sense of the ship and as a second
            second second officers are all
            there is a second officer to the
            Enterprise to the Enterprise.

                    PICARD
                (to com)
            Computer, locate the ship and the
            Enterprise is the ship and the
            Enterprise is the ship and the
            Enterprise is the ship and the
            Enterprise is the ship and all
            the ship is a little second three
            hundred thousand three hundred
            thousand three hundred thousand
            that the contract with the ship
            and the ship is a second on the
            Enterprise.

                    PICARD
                (to com)
            The ship is a little distance of
            the ship and the ship is a little
            distance to the ship and the ship
            is a little band of a second on
            the Enterprise.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
Here the model is making the safest possible predictions, and it ends up almost exclusively generating dialogue by Captain Picard (sometimes there is some Commander Riker dialogue too). It also repeats itself a lot, as if stuck in some kind of loop.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Temperature = 0.75&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;21   INT. NEEDED GEORDI (OPTICAL)

    as he heads toward them and DROPPING SOUNDS.

                    DATA
            Sir, that is not advantaged at
            several days onboard to bodily
            human are weak. We have learned
            a stature of the past... literard
            on the Stargazer&amp;#39;s power range,
            the Enterprise is a personal
            board and transported. You lost
            them estimate a logs as far and
            deck enough as she fights.

                    RIKER
            Unless the band of generators with
            me in it. Only the power took a
            living graviton development.

                    WORF
            Return to your legs?

                    PICARD
                (faster historical)
            I don&amp;#39;t think you would participate
            himself.

                    PICARD
            What he were so quite clear?

                    RIKER
            I can&amp;#39;t point this bad former --
            much decision.

    Kyle shines from his words and the shuttle at his
    head.

      STAR TREK: &amp;quot;Data&amp;#39;s Day&amp;quot; - REV. 10/15/90 - ACT TWO      27.

33A  CONTINUED:

                    PICARD
            I&amp;#39;m sure this is that the report
            knows what comes.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
A pretty good sweet-spot seems to be somewhere around Temperature of 0.75, where we get quite varied output, with very few spelling mistakes.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Despite the fact that the model is a long way off generating a full script, or even any meaningful dialogue, I find the results to be absolutely amazing.&lt;/p&gt;
&lt;p&gt;Remember that this is a single character model that works one letter at a time, and does not know anything about words, punctuation or script-writing rules. And yet, not only does it generate proper English words, but it also has learned a number of quite complex rules.&lt;/p&gt;
&lt;p&gt;For a start all of the lines have almost perfect indentation and line-length:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Original Script:&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;                PICARD
        You will agree, Data, that
        Starfleet&amp;#39;s instructions are
        difficult?
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
&lt;em&gt;Generated Output:&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;                PICARD
        Begin and it has already also
        get a long...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
Furthermore, it has figured out that episode names have a particular format, including a name (enclosed in quotation marks), a date and an act:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Original Script:&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;      STAR TREK: &amp;quot;Haven&amp;quot; - 7/13/87 - ACT THREE
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
&lt;em&gt;Generated Output:&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    STAR TREK: &amp;quot;The Shroud&amp;quot; - 2/1/88 - ACT FIVE
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
It includes dialogue and scene notes and correctly opens and closes brackets:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;                BEVERLY
            (moves quickly to Riker)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br /&gt;
Yes, the model is a lot more complex than the Markov Chain-based models I introduced earlier, but the results are also far superior.&lt;/p&gt;
&lt;p&gt;The single-character markov chain model was only able to generate a little bit of gibberish followed by blank spaces, and even the 5-gram Markov Chain model did not produce anything as accurate as the RNN.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Notes&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;A big thanks to Andrej Karpathy for his &lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/"&gt;blog post&lt;/a&gt; which inspired me to look at RNNs as single-character language models.&lt;/p&gt;
&lt;p&gt;I also found &lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;Christopher Olah's blog post on LSTMs&lt;/a&gt; to be one of the clearer explanations out there.&lt;/p&gt;
&lt;p&gt;Accompanying code is on &lt;a href="https://github.com/simonb83/rnn_star_trek"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="data-science"></category><category term="machine-learning"></category><category term="neural-network"></category></entry><entry><title>Visualizing Pollution in Mexico City - Part II</title><link href="https://simonb83.github.io/visualizing-pollution-part-2.html" rel="alternate"></link><published>2016-11-12T12:00:00-06:00</published><updated>2016-11-12T12:00:00-06:00</updated><author><name>Simon Bedford</name></author><id>tag:simonb83.github.io,2016-11-11:visualizing-pollution-part-2.html</id><summary type="html">&lt;p&gt;A few weeks ago I posted &lt;a href="/visualizing-pollution.html"&gt;some visualizations of pollution levels in Mexico City&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Since then, I discovered a really cool mapping library called &lt;a href="https://carto.com/"&gt;Cartodb&lt;/a&gt;, which also allows you to put together temporal animations, and I decided to test them out on some of the pollution data I had collected.&lt;/p&gt;
&lt;h4&gt;Methodology&lt;/h4&gt;
&lt;p&gt;Here I look at the best and worst weeks for Ozone levels so far in 2016, with worst being defined as the week with the highest total number of bad or worse Ozone measurements, and best being the week with the lowest average measurement.&lt;/p&gt;
&lt;p&gt;In order to deal with missing data, for each station at each hour interval I averaged the readings across the days of the week. This means that for example for the station with code 'SFE', the value used at 01:00 AM is the average of the values at 01:00 AM for each day during the week at that station.&lt;/p&gt;
&lt;p&gt;Finally, in order to create smoother animations and visualizations, I used linear interpolation to transform the measurements from hourly to per-minute frequency.&lt;/p&gt;
&lt;p&gt;Thus what we are really looking at is an 'average' day at 1 minute intervals across the city in both the worst and best weeks of the year.&lt;/p&gt;
&lt;h4&gt;Worst Week: 04 Apr - 10 Apr&lt;/h4&gt;
&lt;p&gt;The map below is an animation of how Ozone measurements evolve at each of the measuring stations throughout the course of the average day, from midnight through to midnight.&lt;/p&gt;
&lt;p&gt;The ozone measurement is encoded using both color and size, such that a good reading is represented by a small, dark green circle, and a bad one by a large dark red circle.&lt;/p&gt;
&lt;p&gt;Press the play button at the bottom of the map to run the animation.&lt;/p&gt;
&lt;div id="dynamic_1" class="map-dynamic"&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="pollution_legend" src="/images/pol2_legend.png" /&gt;&lt;/p&gt;
&lt;p&gt;The 'best' time of the day is around 5 or 6 AM, and then I think it is quite fascinating seeing the ozone levels suddenly start to grow around 9 or 10 o'clock in the morning.&lt;/p&gt;
&lt;p&gt;The 'worst' hour is at 15:00 PM...below is a static view of what the city looks like at this time.&lt;/p&gt;
&lt;div id="map" class="map"&gt;&lt;/div&gt;

&lt;h4&gt;Best Week: 26 Sep - 02 Oct&lt;/h4&gt;
&lt;p&gt;Now let's compare this to the best week.&lt;/p&gt;
&lt;div id="dynamic_2" class="map-dynamic"&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="pollution_legend" src="/images/pol2_legend.png" /&gt;&lt;/p&gt;
&lt;p&gt;The difference is very clear, and even during the peak part of the day, the ozone measurments never really get into orange or red territory.&lt;/p&gt;
&lt;p&gt;In this week the 'worst' hour is at 14:00 PM, and even here the picture of the city looks so much better.&lt;/p&gt;
&lt;div id="map-2" class="map"&gt;&lt;/div&gt;</summary><category term="data-science"></category><category term="visualization"></category></entry><entry><title>Visualizing Pollution in Mexico City</title><link href="https://simonb83.github.io/visualizing-pollution.html" rel="alternate"></link><published>2016-10-30T15:20:00-06:00</published><updated>2016-10-30T15:20:00-06:00</updated><author><name>Simon Bedford</name></author><id>tag:simonb83.github.io,2016-10-30:visualizing-pollution.html</id><summary type="html">&lt;p&gt;Mexico City, where I currently live, is well-known for its poor air quality and high levels of pollution.&lt;/p&gt;
&lt;p&gt;As for any very large city, one of the key challenges is the sheer number of cars on the road. Indeed one &lt;a href="http://www.excelsior.com.mx/comunidad/2016/03/16/1081206"&gt;recent report&lt;/a&gt; indicates that there are now more than 5.5 million vehicles in daily circulation within the metropolitan area, with 250,000 new vehicles added anually.&lt;/p&gt;
&lt;p&gt;One of the measures that has been taken by the authorities, introduced in 1989, tries to reduce both traffic as well as associated pollution through a program called 'Hoy No Circula' (literally 'Does Not Circulate Today') whereby vehicles are prohibited from public circulation on a revolving basis dependent on the last digit of their license plates.&lt;/p&gt;
&lt;p&gt;In practice, the digits are grouped into pairs so that on one day cars with license plates ending in 1 &amp;amp; 2 are prohibited, on another day 3 &amp;amp; 4 and so on.&lt;/p&gt;
&lt;p&gt;The main thing that dictates whether or not your vehicle is subject to the Hoy No Circula regulations is the outcome of mandatory emissions testing which must be carried out twice a year. Based on the test results, you are given a 'hologram' designation of 0, 1 or 2 (so called because after every test a holographic sticker is fixed to the inside of your windscreen), and cars obtaining a '0' are exempt from the program.&lt;/p&gt;
&lt;p&gt;(Brand new cars start out with an automatic '00' rating which is also exempt from Hoy No Circula, and additionally these cars do not require emissions-testing for the first 2 years of their life)&lt;/p&gt;
&lt;p&gt;Ever since moving to Mexico in 2008, I have been lucky enough to be relatively unaffacted by these restictions, aside from the twice-yearly nightmare of trying to get my car tested (a story best kept for a different day).&lt;/p&gt;
&lt;p&gt;However, in March of this year, the authorities announced that there would be extraordinary measures taken due to particularly bad and dangerous pollution levels whereby all cars, indpendent of their hologram, would by subject to the Hoy No Circula program for one day a week and one saturday every month.&lt;/p&gt;
&lt;p&gt;At first it was slightly irritating to have to get used to the rules, however necessary they were, but in the end I think many people were surprised at how quickly they adapted.&lt;/p&gt;
&lt;p&gt;More relevantly I also got to thinking about some of the underlying questions such as how bad pollution was to warrant these emergency measures, and whether or not the additional restrictions had any impact?&lt;/p&gt;
&lt;p&gt;Recently I have been wanting to practice techniques in Data Visualization, such as experimenting with different types of charts and story-telling with data, and this seemed like a perfect opportunity.&lt;/p&gt;
&lt;p&gt;Fortunately Mexico has made some quite impressive advances in recent years with regards to open data, at least in certain areas, and so it was pretty easy to get hold of some data to play with.&lt;/p&gt;
&lt;p&gt;Before going any further a quick disclaimer: this is merely an exercise in data visualization and I certainly don't claim to be evaluating the effectiveness of these measures in any scientific way.&lt;/p&gt;
&lt;h3&gt;How many cars?&lt;/h3&gt;
&lt;p&gt;A good place to start seems to be looking at the number of vehicles on the road, and how this has evolved over time. For this I was able to obtain data from the National Statistics Office on the number of registered vehicles in each federal entity.&lt;/p&gt;
&lt;p&gt;On the chart below I plot the total number registered vehicles in the area comprising the &lt;a href="https://es.wikipedia.org/wiki/Zona_Metropolitana_del_Valle_de_M%C3%A9xico"&gt;metropolitan zone of the valley of mexico&lt;/a&gt;, split by vehicle type:&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt vehicle_growth" src="/images/pol1_num_vehicles-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;As expected, cars are the most common type of registered vehicle, and the number has grown four-fold since 1980 to nearly 8 million in 2014. It is also telling how growth in cars has accelerated in the past 10 years.&lt;/p&gt;
&lt;p&gt;Between 1980 and 2005, the number of registered cars grew about 2.4% annually but between 2005 and 2014, annual growth was 10.2%!&lt;/p&gt;
&lt;p&gt;To put it another way, on average 100,000 cars were added every year between 1980 and 2005, compared to 300,000 new cars per year in the last 9 years.&lt;/p&gt;
&lt;p&gt;From the graph above it is hard to see what is going on with public transport, so below is a plot of the category on its own:&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt vehicle_growth" src="/images/pol1_public_transport-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;The number of public transport vehicles has also grown, more than doubling from just under 20,000 in 1980 to around 46,000 in 2014.&lt;/p&gt;
&lt;p&gt;Clearly there is something strange going on between 2000 and 2010, but if we take the data at face value, it is clear that public transport growth has lagged behind that of private vehicles, and since 2005 has grown at only 4% per year.&lt;/p&gt;
&lt;p&gt;There are many other interesting questions that could be explored for how transport has changed over the years, however this post is meant to be about pollution, so I will move on for the time being.&lt;/p&gt;
&lt;p&gt;Suffice it to say that the data backs up the report I mentioned earlier, and cars are clearly a big and growing problem for the city.&lt;/p&gt;
&lt;h3&gt;A Baseline for Pollution&lt;/h3&gt;
&lt;p&gt;The body responsible for measuring pollution in Mexico City is part of the Environment Agency and conveniently they make all of their data readily available on their website.&lt;/p&gt;
&lt;p&gt;In general there are many different metrics used for measuring air quality, but in the end I decided to focus on the Ozone levels as there was a lot of emphasis placed on these during the environmental 'contingency' earlier this year.&lt;/p&gt;
&lt;p&gt;The first step is to get some sort of a baseline for the pollution levels prior to 2016. Here is a plot of the daily average Ozone levels across the city in 2015:&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt avg_2015_ozone_levels" src="/images/pol1_daily_avg_pollution_2015-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;The daily data is pretty noisy, but you can still see some evidence of seasonality with October through December being, on average, slightly lower months and April and May slightly higher.&lt;/p&gt;
&lt;p&gt;However this is just the average reading which is quite heavily influenced by lower measurements at nighttime, and so to get a better sense of the overall picture, here is the daily maximum on the same axes:&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_daily_max_pollution_2015-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;As with the average, the maximum Ozone measurements display a slight seasonal trend, and you can also see a pretty large gap between the average and maximum readings.&lt;/p&gt;
&lt;p&gt;The next question I looked at was how pollution levels behave throughout the course of a day:&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_hourly_2015-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;Although there is quite a lot going on in this picture, I think there are a couple of interesting takeways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The overall pattern throughout the course of a day is similar year-round, and not that unexpected, with low Ozone levels early in the morning / late at night and higher levels during the daytime&lt;/li&gt;
&lt;li&gt;One interesting difference between months is that the Ozone levels seem to reach their peak at slightly different times of the day:&lt;ul&gt;
&lt;li&gt;&lt;em&gt;April - August&lt;/em&gt;: 2pm&lt;/li&gt;
&lt;li&gt;&lt;em&gt;February, March &amp;amp; September - November&lt;/em&gt;: 3pm&lt;/li&gt;
&lt;li&gt;&lt;em&gt;January, December&lt;/em&gt;: 4pm&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;So why the additional restrictions?&lt;/h3&gt;
&lt;p&gt;Given that the decision to take the emergency measures was made in March, it seems natural to think that pollution levels must have been a lot worse during the first few months of this year compared to previous years.&lt;/p&gt;
&lt;p&gt;To look into this I compared the Ozone measurements for January - March 2015 and 2016 from a number of perspectives&lt;/p&gt;
&lt;p&gt;The first perspective involves looking at average readings from across the city.&lt;/p&gt;
&lt;p&gt;In practice, the agency responsible for pollution monitoring has a number of measuring stations placed across the city. In my analysis I only included those stations that were in use in both 2015 and 2016, resulting in a total of 33 stations.&lt;/p&gt;
&lt;p&gt;Here is a chart that looks at how the average reading for each station changed from 2015 to 2016:&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_q1_compare-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;It is immediately clear that for all but 4 of the measuring stations, the first quarter readings were worse on average in 2016 compared to 2015.&lt;/p&gt;
&lt;p&gt;However, once again these are averages that are heavily influenced by large portions of the day where the readings are low, and furthermore do not take into account any measure of good or bad readings.&lt;/p&gt;
&lt;p&gt;Along with the raw data, the Environment Agency also publishes a scale of what constitutes a good or bad reading, and for Ozone the scale looks like this:&lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;th style="text-align:left"&gt;Category&lt;/th&gt;
        &lt;th&gt;Ozone (ppb&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Good&lt;/td&gt;
        &lt;td&gt;0 - 70&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Regular&lt;/td&gt;
        &lt;td&gt;71 - 95&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Bad&lt;/td&gt;
        &lt;td&gt;96 -154&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Very Bad&lt;/td&gt;
        &lt;td&gt;155 - 204&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Extremely Bad&lt;/td&gt;
        &lt;td&gt;&gt; 204&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Using these categories, another way to compare 2015 and 2016 could be to look at the number of days where the maximum measurement across the city was outside acceptable limits.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_q1_compare_2-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;On the face of it, 2016 doesn't seem much worse than 2015. How about instead looking at the number of times per day that readings are bad or worse based on all measurements across the city?&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_q1_compare_3-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;From this chart it is clearer that there were more dangerous Ozone readings in 2016 compared to 2015: the bars are generally both darker and taller.&lt;/p&gt;
&lt;p&gt;In fact, in March there were three days in a row with more than 80 bad or worse Ozone measurements across the city.&lt;/p&gt;
&lt;h3&gt;What Happened During the Contingency?&lt;/h3&gt;
&lt;p&gt;As I mentioned earlier, the additional measures required all cars to participate in the Hoy No Circula program, independent of their hologram.&lt;/p&gt;
&lt;p&gt;However during the contingency on some days the pollution levels were judged to be so bad that the restrictions were effectively doubled for those days, that is to say that four rather than just two license plate digits were included.&lt;/p&gt;
&lt;p&gt;The first thing to look at is the number of restrictions per day during the contingency period.&lt;/p&gt;
&lt;p&gt;Here the data comes from a website (&lt;a href="http://www.hoy-no-circula.com.mx/"&gt;www.hoy-no-circula.com.mx&lt;/a&gt;) which provides daily information on the driving restrictions. I used a web scraper to go through all of the days from the first 6 months of this year and extract information on those days where restrictions applied to cars with Hologram 0 or 00.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_restrictions-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;You can see that the additional restrictions started on the 4th of April, with breaks only on Sundays until the end of June. In total there were 6 days of double restrictions.&lt;/p&gt;
&lt;p&gt;The next thing I looked at is whether Ozone levels were any better or worse in 2016 compared to 2015 during this contingency period.&lt;/p&gt;
&lt;p&gt;I used the same types of graphics as in the section above looking at the first 3 months of the year.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_q2_compare-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;Looking at the station averages, the picture is worse than for Jan-March, with all but two measuring stations registering an average reading worse in 2016 than 2015.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_q2_compare_2-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here both 2015 and 2016 look pretty bad, and there is not much between them.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_q2_compare_3-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;This is probably the most persuasive picture and you can see quite clearly that there were many more bad or worse readings across Mexico City in 2016 compared to 2015, particularly in April and May.&lt;/p&gt;
&lt;h3&gt;What about the weather?&lt;/h3&gt;
&lt;p&gt;Pollution levels are about more than just cars on the road, and it is well known that weather behaviour has a strong influence too.&lt;/p&gt;
&lt;p&gt;I did not go into much detail here, however the Environmental Agency does publish weather measurements taken across the city, and I wanted to at least look at the relationship between some weather variables and Ozone levels.&lt;/p&gt;
&lt;p&gt;Below are scatter plots looking at how Ozone readings vary with Pressure, Relative Humidity, Temperature and Wind Speed.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_weather-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;The relationships between these weather variables and Ozone readings are clearly complex, although lower Ozone levels seem to be associated with lower temperatures and higher relative humidity.&lt;/p&gt;
&lt;p&gt;I also looked at the behaviour of these weather variables in the first half of 2015 and 2016. Most notably, 2016 seems to have exhibited lower atmospheric pressure than 2015, and also slightly lower relative humidity, particularly between March and June&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_weather_2-min.png" /&gt;&lt;/p&gt;
&lt;h3&gt;2016 Year-to-date&lt;/h3&gt;
&lt;p&gt;The 'contingency' ended on the 30th of June, and as of writing we are now just two months away from the end of the year. So how has the year been as whole vs. 2015, and what have the past few months looked like in terms of Ozone levels?&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_2015_v_2016-min.png" /&gt;&lt;/p&gt;
&lt;p&gt;The average levels were noticably higher in 2016 during the first half of the year, particularly between April and June, but since then, the levels have more closely mirrored 2015.&lt;/p&gt;
&lt;p&gt;However, this is not to say that dangerous levels of Ozone have disappeared. Although the overall number of bad or worse readings has decreased since June, there have been a significant number of days with multiple high measurements across the city, and the overall picture continues to look worse than last year.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt max_2015_ozone_levels" src="/images/pol1_q3_compare_1-min.png" /&gt;&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;We have seen that on many levels the Ozone pollution levels have been worse this year compared to last, even with the additional driving restrictions, and who knows how much worse the peak months could have been had the contingency not been enacted.&lt;/p&gt;
&lt;p&gt;Perhaps more worryingly, we have also seen that even in months with lower overall Ozone levels, there are still a substantial number of days with multiple measurements outside of acceptable limits.&lt;/p&gt;
&lt;p&gt;The question therefore seems to be not whether the additional driving restrictions were effective, but what more can be done year-round to help reduce dangerous levels of pollutants across the city.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Notes&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;More details of the data sources and accompanying code can be found on &lt;a href="https://github.com/simonb83/mexico-pollution"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;</summary><category term="data-science"></category><category term="visualization"></category></entry><entry><title>Measuring Box Office Success</title><link href="https://simonb83.github.io/measuring-box-office-success.html" rel="alternate"></link><published>2016-10-06T18:20:00-05:00</published><updated>2016-10-06T18:20:00-05:00</updated><author><name>Simon Bedford</name></author><id>tag:simonb83.github.io,2016-10-06:measuring-box-office-success.html</id><summary type="html">&lt;p&gt;During a discussion with my wife about the Batman vs. Superman film from
earlier this year, the question came up as to whether the box office
drop from the opening to the 2nd weekend was normal, or whether it
dropped more than it should have due to bad word of mouth.&lt;/p&gt;
&lt;p&gt;I decided to get hold of some data from the BoxOffice Mojo website to
try and answer this question, and it then also evolved into an exercise
in data visualization.&lt;/p&gt;
&lt;p&gt;The data was all obtained from BoxOfficeMojo using a couple of web
scraping scripts. For additional details, as well as known issues, see
more at
&lt;a class="reference external" href="https://github.com/simonb83/DataScienceIntensive/tree/master/projects/box-office"&gt;https://github.com/simonb83/DataScienceIntensive/tree/master/projects/box-office&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="what-does-success-mean"&gt;
&lt;h2&gt;What does success mean&lt;/h2&gt;
&lt;p&gt;In reality we see that films can be successful in different ways
depending on the metric we use.&lt;/p&gt;
&lt;p&gt;If we look at box office takings for the opening weekend then, as
expected, Sci-Fi, Action and Animated are the genres that typically
dominate.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image1" src="https://simonb83.github.io/images/box_office_image1.png" /&gt;&lt;/p&gt;
&lt;p&gt;However if we also take budget into account, then it turns out that
Horror films are particularly successful.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image2" src="https://simonb83.github.io/images/box_office_image2.png" /&gt;&lt;/p&gt;
&lt;p&gt;When we look into why this might be, we see that on average Horror films
have a budget one quarter of the size of that for Action, SciFi and
Animated films, so it is much easier for them to make their money back.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image3" src="https://simonb83.github.io/images/box_office_image3.png" /&gt;&lt;/p&gt;
&lt;p&gt;When we look further into budgets we see that they have increased
steadily since the 1980s in both nominal and adjusted terms.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image4" src="https://simonb83.github.io/images/box_office_image4.png" /&gt;&lt;/p&gt;
&lt;p&gt;At the same time, the average opening weekend takings seem to have been
on a slight downward trend since 2000.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image5" src="https://simonb83.github.io/images/box_office_image5.png" /&gt;&lt;/p&gt;
&lt;p&gt;This could be because the total number of films released has almost
doubled since 2000, pushing down the box office average.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image6" src="https://simonb83.github.io/images/box_office_image6.png" /&gt;&lt;/p&gt;
&lt;p&gt;In terms of total takings, the vast majority of releases make less than
$25 million in their opening weekend.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image7" src="https://simonb83.github.io/images/box_office_image7.png" /&gt;&lt;/p&gt;
&lt;p&gt;Whilst ‘blockbusters’ continue&amp;nbsp; to break box office records on a regular
basis.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image8" src="https://simonb83.github.io/images/box_office_image8.png" /&gt;&lt;/p&gt;
&lt;p&gt;On average, films drop by about 40% in Box Office takings between their
opening and second weekends.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image9" src="https://simonb83.github.io/images/box_office_image9.png" /&gt;&lt;/p&gt;
&lt;p&gt;That said, there are films that actually increase their box office
takings in their second weekend, although these are typically from more
obscure genres.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image10" src="https://simonb83.github.io/images/box_office_image10.png" /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="batman-vs-superman"&gt;
&lt;h2&gt;Batman vs Superman&lt;/h2&gt;
&lt;p&gt;Now we look at the Batman vs Superman film in more detail and compare
with two specific films:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Avengers: Civil War&lt;/li&gt;
&lt;li&gt;Batman: Dark Knight Rises&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also use a general group consisting of 89 Sci-Fi and Action/Adventure
films, with budget &amp;gt; 100 million USD, released since 2010.Batman vs.
Superman performed very well in its opening weekend.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image11" src="https://simonb83.github.io/images/box_office_image11.png" /&gt;&lt;/p&gt;
&lt;p&gt;It was also within the top 10 films with a highest grossing opening
weekend based on our comparison group:&lt;/p&gt;
&lt;p&gt;&lt;img alt="image12" src="https://simonb83.github.io/images/box_office_image12.png" /&gt;&lt;/p&gt;
&lt;p&gt;However, by the second weekend it did a lot worse than its peers,
dropping nearly 70% vs. an average drop of 50% for similar films.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image13" src="https://simonb83.github.io/images/box_office_image13.png" /&gt;&lt;/p&gt;
&lt;p&gt;Finally, we look at a couple of very simple scenarios for how well BvS
could have performed in its second weekend, had it not dropped more than
average vs. its peer group.&lt;/p&gt;
&lt;p&gt;We find that it could have made an additional $12-30 million in its
second weekend had it performed similar to comparative films.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image14" src="https://simonb83.github.io/images/box_office_image14.png" /&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="exploratory-analysis"></category><category term="visualization"></category><category term="data-science"></category></entry></feed>